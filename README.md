<h1 align="center"> ğŸŒ¿ Soybean Leaf Disease Detection Using Graph Convolutional Networks (GCN) in PyTorch </h1>

This repository presents a pipeline for detecting diseases in soybean leaves using **Graph Convolutional Networks (GCN)**. It classifies leaves into four categories â€” **Healthy**, **Rust**, **Mosaic**, and **Pest** â€” using a relational graph-based approach implemented in PyTorch Geometric.

---

## ğŸ§¾ Project Overview
<div align="center">

| Attribute              | Description                                                                 |
|------------------------|-----------------------------------------------------------------------------|
| ğŸ“š Framework           | PyTorch, PyTorch Geometric, Scikit-learn                                    |
| ğŸ§  Models Used         | Graph Convolutional Network (GCN), Relational GCN                           |
| ğŸ“· Input Format        | Drone-captured Images (~256Ã—256 px)                                         |
| ğŸ¯ Output              | 4-Class Image Classification                                                 |
| ğŸ§ª File                | `gcn-code.ipynb`                                                             |
| ğŸ“ Dataset Source      | [Soybean Leaf Dataset (Kaggle)](https://data.mendeley.com/datasets/hkbgh5s3b7/1) |

</div>

---

## ğŸ—‚ Dataset Overview

This dataset includes drone-captured images of soybean plants from various growth stages, classified into four types based on the disease:

<h3 align="center">ğŸ“Š Class Distribution</h3>

<table align="center">
  <tr>
    <td align="center"><img src="Sample_Input_Images/healthy.jpg" width="120px"></td>
    <td align="center"><img src="Sample_Input_Images/rust.jpg" width="120px"></td>
    <td align="center"><img src="Sample_Input_Images/mosaic.jpg" width="120px"></td>
    <td align="center"><img src="Sample_Input_Images/pest.jpg" width="120px"></td>
  </tr>
  <tr>
    <td align="center"><b>Healthy</b></td>
    <td align="center"><b>Rust</b></td>
    <td align="center"><b>Mosaic</b></td>
    <td align="center"><b>Pest</b></td>
  </tr>
</table>

- Total Images: ~1,000+  
- Format: `.jpg`  
- Structure: Class-wise folders  
- Preprocessing: Resizing, patch extraction, graph construction  

---

## ğŸ§ª Notebook Workflow
<div align="center">
  
| Step                | Description                                                                 |
|---------------------|-----------------------------------------------------------------------------|
| ğŸ“¥ Data Loading      | Dataset parsed and structured into graph format                             |
| ğŸ§¼ Preprocessing      | Image â†’ Superpixels â†’ Graph (nodes/edges)                                  |
| ğŸ§  Model              | R-GCN architecture using PyTorch Geometric                                  |
| ğŸ” Training           | CrossEntropyLoss + Adam optimizer                                           |
| ğŸ“Š Evaluation         | Accuracy, Confusion Matrix, ROC-AUC, Graph Visuals                          |
| ğŸ” Inference          | Predict class for new images using trained GCN                             |

</div>

---

<h2>âš™ï¸ Model Configuration &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ğŸ“ˆ Performance Summary</h2>
<div align="center">
<table>
  <tr>
    <td>

<!-- Left Table -->
<b>âš™ï¸ Model Configuration</b>

<table>
  <tr><th>Parameter</th><th>Value</th></tr>
  <tr><td>Graph Layers</td><td>R-GCN (2-layer)</td></tr>
  <tr><td>Input Features</td><td>16</td></tr>
  <tr><td>Hidden Features</td><td>32</td></tr>
  <tr><td>Output Classes</td><td>4</td></tr>
  <tr><td>Optimizer</td><td>Adam</td></tr>
  <tr><td>Loss Function</td><td>CrossEntropy</td></tr>
  <tr><td>Batch Size</td><td>32</td></tr>
</table>

  </td>
  <td style="width: 40px;"></td>
  <td>

<!-- Right Table -->
<b>ğŸ“ˆ Performance Summary</b>

<table>
  <tr><th>Metric</th><th>Value</th></tr>
  <tr><td>âœ… Final Accuracy</td><td><b>94.50%</b></td></tr>
  <tr><td>ğŸ” ROC-AUC</td><td><b>0.96 (macro avg)</b></td></tr>
  <tr><td>ğŸ“‰ Final Loss</td><td><b>0.217</b></td></tr>
  <tr><td>ğŸ“Š Confusion Matrix</td><td>4Ã—4</td></tr>
</table>

  </td>
  </tr>
</table>
</div>

---

## ğŸ“Š Model Outputs

<p align="center">
  <img src="Output_Images/Accuracy_Curve.png" height="220px" style="margin-right: 10px;">
  <img src="Output_Images/Loss_Curve.png" height="220px">
</p>

<p align="center">
  <img src="Output_Images/Confusion_Matrix.png" height="220px" style="margin-right: 10px;">
  <img src="Output_Images/ROC_Curve.png" height="220px">
</p>

<p align="center">
  <img src="Output_Images/Graph_Visualization.png" height="220px" style="margin-right: 10px;">
  <img src="System_Architecture_Images/Flow_Diagram.png" height="220px">
</p>

---

## âœ… Conclusion

This work shows that **Graph Neural Networks** â€” specifically **Relational GCNs** â€” can effectively model spatial and topological relationships within drone-captured crop images, achieving over **94% accuracy** in detecting:

- ğŸŸ¢ Healthy
- ğŸ‚ Rust
- ğŸ§¬ Mosaic
- ğŸ› Pest

GCNs provide a compact, explainable architecture for crop health monitoring and precision agriculture.

---

## ğŸ”® Future Enhancements

- ğŸ›°ï¸ **Integrate remote sensing data** (NDVI, multispectral)  
- ğŸŒ **Real-time GCN inference** using ONNX or TensorRT  
- ğŸ” **Model Explainability** using Graph Attention or Grad-CAM  
- ğŸš€ **Deploy with Flask/Streamlit** for mobile/web-based monitoring  
- ğŸ§ª Test **GAT / GIN / ChebNet** for improved disease segmentation  

---

## ğŸš€ Getting Started

#### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/soybean-gcn.git
cd soybean-gcn
